11.1. Array API support (experimental) — scikit-learn 1.4.1 documentation Install User Guide API Examples Community Getting Started Tutorial What's new Glossary Development FAQ Support Related packages Roadmap Governance About us GitHub Other Versions and Download More Getting Started Tutorial What's new Glossary Development FAQ Support Related packages Roadmap Governance About us GitHub Other Versions and Download Toggle Menu PrevUp Next scikit-learn 1.4.1 Other versions Please cite us if you use the software. User Guide 1. Supervised learning 2. Unsupervised learning 3. Model selection and evaluation 4. Inspection 5. Visualizations 6. Dataset transformations 7. Dataset loading utilities 8. Computing with scikit-learn 9. Model persistence 10. Common pitfalls and recommended practices 11. Dispatching 11.1. Array API support (experimental) 11.1. Array API support (experimental)¶ The Array API specification defines a standard API for all array manipulation libraries with a NumPy-like API. Scikit-learn’s Array API support requires array-api-compat to be installed. Some scikit-learn estimators that primarily rely on NumPy (as opposed to using Cython) to implement the algorithmic logic of their fit, predict or transform methods can be configured to accept any Array API compatible input datastructures and automatically dispatch operations to the underlying namespace instead of relying on NumPy. At this stage, this support is considered experimental and must be enabled explicitly as explained in the following. Note Currently, only cupy.array_api, numpy.array_api, cupy, and PyTorch are known to work with scikit-learn’s estimators. 11.1.1. Example usage¶ Here is an example code snippet to demonstrate how to use CuPy to run LinearDiscriminantAnalysis on a GPU: >>> from sklearn.datasets import make_classification >>> from sklearn import config_context >>> from sklearn.discriminant_analysis import LinearDiscriminantAnalysis >>> import cupy >>> X_np, y_np = make_classification(random_state=0) >>> X_cu = cupy.asarray(X_np) >>> y_cu = cupy.asarray(y_np) >>> X_cu.device <CUDA Device 0> >>> with config_context(array_api_dispatch=True): ... lda = LinearDiscriminantAnalysis() ... X_trans = lda.fit_transform(X_cu, y_cu) >>> X_trans.device <CUDA Device 0> After the model is trained, fitted attributes that are arrays will also be from the same Array API namespace as the training data. For example, if CuPy’s Array API namespace was used for training, then fitted attributes will be on the GPU. We provide a experimental _estimator_with_converted_arrays utility that transfers an estimator attributes from Array API to a ndarray: >>> from sklearn.utils._array_api import _estimator_with_converted_arrays >>> cupy_to_ndarray = lambda array : array.get() >>> lda_np = _estimator_with_converted_arrays(lda, cupy_to_ndarray) >>> X_trans = lda_np.transform(X_np) >>> type(X_trans) <class 'numpy.ndarray'> 11.1.1.1. PyTorch Support¶ PyTorch Tensors are supported by setting array_api_dispatch=True and passing in the tensors directly: >>> import torch >>> X_torch = torch.asarray(X_np, device="cuda", dtype=torch.float32) >>> y_torch = torch.asarray(y_np, device="cuda", dtype=torch.float32) >>> with config_context(array_api_dispatch=True): ... lda = LinearDiscriminantAnalysis() ... X_trans = lda.fit_transform(X_torch, y_torch) >>> type(X_trans) <class 'torch.Tensor'> >>> X_trans.device.type 'cuda' 11.1.2. Support for Array API-compatible inputs¶ Estimators and other tools in scikit-learn that support Array API compatible inputs. 11.1.2.1. Estimators¶ decomposition.PCA (with svd_solver="full", svd_solver="randomized" and power_iteration_normalizer="QR") discriminant_analysis.LinearDiscriminantAnalysis (with solver="svd") preprocessing.KernelCenterer preprocessing.MaxAbsScaler preprocessing.MinMaxScaler preprocessing.Normalizer 11.1.2.2. Metrics¶ sklearn.metrics.accuracy_score sklearn.metrics.zero_one_loss 11.1.2.3. Tools¶ model_selection.train_test_split Coverage is expected to grow over time. Please follow the dedicated meta-issue on GitHub to track progress. 11.1.3. Common estimator checks¶ Add the array_api_support tag to an estimator’s set of tags to indicate that it supports the Array API. This will enable dedicated checks as part of the common tests to verify that the estimators result’s are the same when using vanilla NumPy and Array API inputs. To run these checks you need to install array_api_compat in your test environment. To run the full set of checks you need to install both PyTorch and CuPy and have a GPU. Checks that can not be executed or have missing dependencies will be automatically skipped. Therefore it’s important to run the tests with the -v flag to see which checks are skipped: pip install array-api-compat # and other libraries as needed pytest -k "array_api" -v 11.1.3.1. Note on MPS device support¶ On macOS, PyTorch can use the Metal Performance Shaders (MPS) to access hardware accelerators (e.g. the internal GPU component of the M1 or M2 chips). However, the MPS device support for PyTorch is incomplete at the time of writing. See the following github issue for more details: https://github.com/pytorch/pytorch/issues/77764 To enable the MPS support in PyTorch, set the environment variable PYTORCH_ENABLE_MPS_FALLBACK=1 before running the tests: PYTORCH_ENABLE_MPS_FALLBACK=1 pytest -k "array_api" -v At the time of writing all scikit-learn tests should pass, however, the computational speed is not necessarily better than with the CPU device. © 2007 - 2024, scikit-learn developers (BSD License). Show this page source