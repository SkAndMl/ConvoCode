4. Inspection — scikit-learn 1.4.1 documentation Install User Guide API Examples Community Getting Started Tutorial What's new Glossary Development FAQ Support Related packages Roadmap Governance About us GitHub Other Versions and Download More Getting Started Tutorial What's new Glossary Development FAQ Support Related packages Roadmap Governance About us GitHub Other Versions and Download Toggle Menu PrevUp Next scikit-learn 1.4.1 Other versions Please cite us if you use the software. User Guide 1. Supervised learning 2. Unsupervised learning 3. Model selection and evaluation 4. Inspection 4.1. Partial Dependence and Individual Conditional Expectation plots 4.2. Permutation feature importance 5. Visualizations 6. Dataset transformations 7. Dataset loading utilities 8. Computing with scikit-learn 9. Model persistence 10. Common pitfalls and recommended practices 11. Dispatching 4. Inspection¶ Predictive performance is often the main goal of developing machine learning models. Yet summarizing performance with an evaluation metric is often insufficient: it assumes that the evaluation metric and test dataset perfectly reflect the target domain, which is rarely true. In certain domains, a model needs a certain level of interpretability before it can be deployed. A model that is exhibiting performance issues needs to be debugged for one to understand the model’s underlying issue. The sklearn.inspection module provides tools to help understand the predictions from a model and what affects them. This can be used to evaluate assumptions and biases of a model, design a better model, or to diagnose issues with model performance. Examples: Common pitfalls in the interpretation of coefficients of linear models 4.1. Partial Dependence and Individual Conditional Expectation plots 4.1.1. Partial dependence plots 4.1.2. Individual conditional expectation (ICE) plot 4.1.3. Mathematical Definition 4.1.4. Computation methods 4.2. Permutation feature importance 4.2.1. Outline of the permutation importance algorithm 4.2.2. Relation to impurity-based importance in trees 4.2.3. Misleading values on strongly correlated features © 2007 - 2024, scikit-learn developers (BSD License). Show this page source