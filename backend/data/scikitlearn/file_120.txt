2. Unsupervised learning — scikit-learn 1.4.1 documentation Install User Guide API Examples Community Getting Started Tutorial What's new Glossary Development FAQ Support Related packages Roadmap Governance About us GitHub Other Versions and Download More Getting Started Tutorial What's new Glossary Development FAQ Support Related packages Roadmap Governance About us GitHub Other Versions and Download Toggle Menu PrevUp Next scikit-learn 1.4.1 Other versions Please cite us if you use the software. User Guide 1. Supervised learning 2. Unsupervised learning 2.1. Gaussian mixture models 2.2. Manifold learning 2.3. Clustering 2.4. Biclustering 2.5. Decomposing signals in components (matrix factorization problems) 2.6. Covariance estimation 2.7. Novelty and Outlier Detection 2.8. Density Estimation 2.9. Neural network models (unsupervised) 3. Model selection and evaluation 4. Inspection 5. Visualizations 6. Dataset transformations 7. Dataset loading utilities 8. Computing with scikit-learn 9. Model persistence 10. Common pitfalls and recommended practices 11. Dispatching 2. Unsupervised learning¶ 2.1. Gaussian mixture models 2.1.1. Gaussian Mixture 2.1.2. Variational Bayesian Gaussian Mixture 2.2. Manifold learning 2.2.1. Introduction 2.2.2. Isomap 2.2.3. Locally Linear Embedding 2.2.4. Modified Locally Linear Embedding 2.2.5. Hessian Eigenmapping 2.2.6. Spectral Embedding 2.2.7. Local Tangent Space Alignment 2.2.8. Multi-dimensional Scaling (MDS) 2.2.9. t-distributed Stochastic Neighbor Embedding (t-SNE) 2.2.10. Tips on practical use 2.3. Clustering 2.3.1. Overview of clustering methods 2.3.2. K-means 2.3.3. Affinity Propagation 2.3.4. Mean Shift 2.3.5. Spectral clustering 2.3.6. Hierarchical clustering 2.3.7. DBSCAN 2.3.8. HDBSCAN 2.3.9. OPTICS 2.3.10. BIRCH 2.3.11. Clustering performance evaluation 2.4. Biclustering 2.4.1. Spectral Co-Clustering 2.4.2. Spectral Biclustering 2.4.3. Biclustering evaluation 2.5. Decomposing signals in components (matrix factorization problems) 2.5.1. Principal component analysis (PCA) 2.5.2. Kernel Principal Component Analysis (kPCA) 2.5.3. Truncated singular value decomposition and latent semantic analysis 2.5.4. Dictionary Learning 2.5.5. Factor Analysis 2.5.6. Independent component analysis (ICA) 2.5.7. Non-negative matrix factorization (NMF or NNMF) 2.5.8. Latent Dirichlet Allocation (LDA) 2.6. Covariance estimation 2.6.1. Empirical covariance 2.6.2. Shrunk Covariance 2.6.3. Sparse inverse covariance 2.6.4. Robust Covariance Estimation 2.7. Novelty and Outlier Detection 2.7.1. Overview of outlier detection methods 2.7.2. Novelty Detection 2.7.3. Outlier Detection 2.7.4. Novelty detection with Local Outlier Factor 2.8. Density Estimation 2.8.1. Density Estimation: Histograms 2.8.2. Kernel Density Estimation 2.9. Neural network models (unsupervised) 2.9.1. Restricted Boltzmann machines © 2007 - 2024, scikit-learn developers (BSD License). Show this page source